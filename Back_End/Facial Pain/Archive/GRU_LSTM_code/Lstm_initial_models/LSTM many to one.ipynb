{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many to One (Label is last element in sequence) (One output per sequence) (No Shuffling or batching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the csv files and pre processing to remove header and delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_pain = np.loadtxt('C:/Users/Nischal/Desktop/BioVid_split/pain/Pain_features_and_labels_071309_w_21_pain.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "xy_nopain = np.loadtxt('C:/Users/Nischal/Desktop/BioVid_split/no_pain/Pain_features_and_labels_071309_w_21_no_pain.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "\n",
    "## Making pain and no pain classes to be of equal sizes\n",
    "x_p=(xy_pain[:,:-1])\n",
    "y_p=(xy_pain[:,[-1]])\n",
    "x_np=(xy_nopain[:len(x_p),:-1])\n",
    "y_np=(xy_nopain[:len(x_p),[-1]])\n",
    "# print(len(x_np[0]),len(x_p))\n",
    "\n",
    "###### Test train split:\n",
    "train=np.round(len(x_p)*0.7)\n",
    "test=len(x_p)-train\n",
    "\n",
    "x_p_train= (x_p[:int(train)])\n",
    "x_p_test = (x_p[int(train):])\n",
    "\n",
    "y_p_train= y_p[:int(train)]\n",
    "y_p_test = y_p[int(train):]\n",
    "\n",
    "x_np_train= (x_np[:int(train)])\n",
    "x_np_test = (x_np[int(train):])\n",
    "\n",
    "y_np_train= y_np[:int(train)]\n",
    "y_np_test = y_np[int(train):]\n",
    "\n",
    "x_train= np.vstack((x_p_train,x_np_train))\n",
    "x_test = np.vstack((x_p_test,x_np_test))\n",
    "\n",
    "y_train= np.vstack((y_p_train,y_np_train))\n",
    "y_test = np.vstack((y_p_test,y_np_test))\n",
    "\n",
    "only_pain_test_x = x_p_test\n",
    "only_pain_test_y = y_p_test\n",
    "\n",
    "# print(len(x_test),len(y_train))\n",
    "# print(x_p_train[0])\n",
    "# print(x_np_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a dataset for Pain related frames\n",
    "\n",
    "# xy_pain = np.loadtxt('C:/Users/Nischal/Desktop/BioVid_split/pain/Pain_features_and_labels_071309_w_21_pain.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "# xy_nopain = np.loadtxt('C:/Users/Nischal/Desktop/BioVid_split/no_pain/Pain_features_and_labels_071309_w_21_no_pain.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "# x_p=(xy_pain[:,:-1])\n",
    "# y_p=(xy_pain[:,[-1]])\n",
    "# x_np=(xy_nopain[:,:-1])\n",
    "# y_np=(xy_nopain[:,[-1]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lstm_data_transform(x_data, y_data, num_steps=30):\n",
    "    \"\"\" Changes data to the format for LSTM training \n",
    "for sliding window approach \"\"\"\n",
    "    # Prepare the list for the transformed data\n",
    "    X, y = list(), list()\n",
    "    # Loop of the entire data set\n",
    "    for i in range(x_data.shape[0]):\n",
    "        # compute a new (sliding window) index\n",
    "        end_ix = i + num_steps\n",
    "        # if index is larger than the size of the dataset, we stop\n",
    "        if end_ix >= x_data.shape[0]:\n",
    "            break\n",
    "        # Get a sequence of data for x\n",
    "        seq_X = x_data[i:end_ix]\n",
    "        # Get only the last element of the sequency for y\n",
    "        seq_y = y_data[end_ix]\n",
    "        # Append the list with sequencies\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "    # Make final arrays\n",
    "    x_array = np.array(X)\n",
    "    y_array = np.array(y)\n",
    "    x=torch.from_numpy(x_array)\n",
    "    y=torch.from_numpy(y_array)\n",
    "    return x, y\n",
    "\n",
    "## Sequence processing test and train data\n",
    "\n",
    "train_x,train_y=lstm_data_transform(x_train,y_train)\n",
    "test_x,test_y=lstm_data_transform(x_test,y_test)\n",
    "\n",
    "## Only test for pain\n",
    "\n",
    "OP_test_x,OP_test_y=lstm_data_transform(only_pain_test_x,only_pain_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1492e4f6898>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPUklEQVR4nO3df6zdd13H8eeL222iGwzohcz+sCUWtDEbjsuYQXT4g7WbsZqYuCEOF5ZmCTMYY6SEiDH8haghyKBpsBmLSv9hSMXiJAryx5ysk22sjI5LN9i1096JIj8SZ9nbP863ePhy23vWfU9vbz/PR3Jzz/fz/ZzT9+eb3vu63+/5nM83VYUkqT3PWukCJEkrwwCQpEYZAJLUKANAkhplAEhSo9as1D+8du3a2rRp00r985K0Kt17771PVNXsEK+1YgGwadMmDh48uFL/vCStSkm+PNRreQlIkhplAEhSowwASWqUASBJjTIAJKlRywZAkr1JjiV58CT7k+Q9SeaTPJDk8uHLlCQNbZIzgNuAbafYvx3Y0n3tBN7/zMuSJE3bsp8DqKpPJ9l0ii47gNtrtK703UkuTnJJVT0+UI3f5fC/fZ2/eeDoNF5a4oLzZnj9lT/Ec5993kqXIk3dEB8EWwc8Nra90LV9TwAk2cnoLIGNGzee1j82f+wb/Okn50/rudKpnLg1xvrnPZsdL1u3ssVIZ8AQAZAl2pa8y0xV7QH2AMzNzZ3WnWiuvfQSrr302tN5qnRKjz7xTa76o0/xlDdJUiOGmAW0AGwY214PeI1Gks5yQwTAfuCGbjbQlcDXpnX9X5I0nGUvASX5EHAVsDbJAvD7wHkAVbUbOABcA8wD3wJunFaxkqThTDIL6Ppl9hfwpsEqkiSdEX4SWOrxPWC1wgCQOllqPpt0DjMAJKlRBoAkNcoAkKRGGQCS1CgDQOpxFpBaYQBInSy5rJV07jIAJKlRBoAkNcoAkKRGGQCS1CgDQOpxEpBaYQBIHdcCUmsMAElqlAEgSY0yACSpUQaAJDXKAJB6ysWA1AgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaA1OMcILXCAJA6rgWk1hgAktQoA0CSGmUASFKjDABJapQBIPU5DUiNmCgAkmxLcjjJfJJdS+x/bpK/TnJ/kkNJbhy+VGm64jQgNWbZAEgyA9wKbAe2Atcn2drr9ibg81V1GXAV8MdJzh+4VknSgCY5A7gCmK+qI1X1JLAP2NHrU8BFGf0JdSHwVeD4oJVKkgY1SQCsAx4b217o2sa9F/hR4CjwOeDNVfVU/4WS7ExyMMnBxcXF0yxZkjSESQJgqQuj/bfJrgbuA34QeBnw3iTP+Z4nVe2pqrmqmpudnX3axUqShjNJACwAG8a21zP6S3/cjcAdNTIPPAL8yDAlSmdWOQ1IjZgkAO4BtiTZ3L2xex2wv9fnK8DPAiR5EfBS4MiQhUrT5hwgtWbNch2q6niSW4A7gRlgb1UdSnJzt3838A7gtiSfY/Rz9JaqemKKdUuSnqFlAwCgqg4AB3ptu8ceHwVeO2xpkqRp8pPAktQoA0DqKd8DViMMAElqlAEgdVwKSK0xACSpUQaAJDXKAJCkRhkAUo+TgNQKA0CSGmUASJ24GpAaYwBIUqMMAElqlAEgSY0yAKQe1wJSKwwASWqUASB1XAtIrTEAJKlRBoAkNcoAkKRGGQBST7kakBphAEhSowwAqeMkILXGAJCkRhkAktQoA0CSGmUASD2uBaRWGACS1CgDQDrBaUBqjAEgSY0yACSpURMFQJJtSQ4nmU+y6yR9rkpyX5JDSf5x2DIlSUNbs1yHJDPArcDPAwvAPUn2V9Xnx/pcDLwP2FZVX0nywmkVLE2bk4DUiknOAK4A5qvqSFU9CewDdvT6vA64o6q+AlBVx4YtU5I0tEkCYB3w2Nj2Qtc27iXA85J8Ksm9SW5Y6oWS7ExyMMnBxcXF06tYmpI4DUiNmSQAlvqp6J8lrwFeDlwLXA38XpKXfM+TqvZU1VxVzc3Ozj7tYiVJw1n2PQBGf/FvGNteDxxdos8TVfVN4JtJPg1cBjw8SJWSpMFNcgZwD7AlyeYk5wPXAft7fT4KvDrJmiTfD7wSeGjYUiVJQ1r2DKCqjie5BbgTmAH2VtWhJDd3+3dX1UNJ/hZ4AHgK+EBVPTjNwqWpcTEgNWKSS0BU1QHgQK9td2/7XcC7hitNkjRNfhJY6sRJQGqMASBJjTIAJKlRBoAkNcoAkHqcA6RWGACS1CgDQOo4CUitMQAkqVEGgCQ1ygCQpEYZAFKPSwGpFQaAJDXKAJA6cTEgNcYAkKRGGQCS1CgDQJIaZQBIPeU0IDXCAJCkRhkAUsc5QGqNASBJjTIAJKlRBoAkNcoAkHqcA6RWGACS1CgDQOq4FJBaYwBIUqMMAElqlAEgSY0yAKQelwJSKwwASWqUASB14mpAasxEAZBkW5LDSeaT7DpFv1ck+XaSXxmuREnSNCwbAElmgFuB7cBW4PokW0/S753AnUMXKUka3iRnAFcA81V1pKqeBPYBO5bo95vAh4FjA9YnSZqSSQJgHfDY2PZC1/YdSdYBvwzsPtULJdmZ5GCSg4uLi0+3VumMcBKQWjFJACz1zlj/Z+TdwFuq6tuneqGq2lNVc1U1Nzs7O2mNkqQpWDNBnwVgw9j2euBor88csC+jxVTWAtckOV5VfzVIldKZ4CQgNWaSALgH2JJkM/CvwHXA68Y7VNXmE4+T3AZ8zF/+knR2WzYAqup4klsYze6ZAfZW1aEkN3f7T3ndX5J0dprkDICqOgAc6LUt+Yu/qn7jmZclSZo2Pwks9ZSLAakRBoAkNcoAkDreEUytMQAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEgdJwGpNQaAJDXKAJCkRhkAktQoA0DqcSkgtcIAkKRGGQBSJy4GpMYYAJLUKANAkhplAEhSowwAqadwGpDaYABIUqMMAKnjHCC1xgCQpEYZAJLUKANAkhplAEg9rgWkVhgAktQoA0DquBSQWmMASFKjDABJapQBIEmNmigAkmxLcjjJfJJdS+z/tSQPdF93Jbls+FKlM8NJQGrFsgGQZAa4FdgObAWuT7K11+0R4Ker6lLgHcCeoQuVJA1rkjOAK4D5qjpSVU8C+4Ad4x2q6q6q+s9u825g/bBlStMXVwNSYyYJgHXAY2PbC13bybwR+PhSO5LsTHIwycHFxcXJq5QkDW6SAFjqz6IlL5MmeQ2jAHjLUvurak9VzVXV3Ozs7ORVSpIGt2aCPgvAhrHt9cDRfqcklwIfALZX1X8MU54kaVomOQO4B9iSZHOS84HrgP3jHZJsBO4Afr2qHh6+TOnMcS0gtWLZM4CqOp7kFuBOYAbYW1WHktzc7d8NvB14AfC+jD5Pf7yq5qZXtiTpmZrkEhBVdQA40GvbPfb4JuCmYUuTzizXAlJr/CSwJDXKAJCkRhkAktQoA0DqKVcDUiMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAUo9rAakVBoAkNcoAkDquBaTWGACS1CgDQJIaZQBIUqMMAElqlAEgSY0yAKROcBqQ2mIASFKjDABJapQBIEmNMgCknnIxIDXCAJA6LgWh1hgAktQoA0CSGmUASFKjDABJapQBIPU4CUitMACkjpOA1BoDQJIaZQBIUqMmCoAk25IcTjKfZNcS+5PkPd3+B5JcPnypkqQhLRsASWaAW4HtwFbg+iRbe922A1u6r53A+weuU5I0sDUT9LkCmK+qIwBJ9gE7gM+P9dkB3F6jRVTuTnJxkkuq6vHBK5am7La7HmX//UdXugydw371FRu46dUvXukyJgqAdcBjY9sLwCsn6LMO+K4ASLKT0RkCGzdufLq1SlO1ZuZZ3PKaH+bIE99Y6VJ0jlt74QUrXQIwWQAsNTuuP1N6kj5U1R5gD8Dc3JyzrXXW+Z2rX7rSJUhnzCRvAi8AG8a21wP98+NJ+kiSziKTBMA9wJYkm5OcD1wH7O/12Q/c0M0GuhL4mtf/JenstuwloKo6nuQW4E5gBthbVYeS3Nzt3w0cAK4B5oFvATdOr2RJ0hAmeQ+AqjrA6Jf8eNvusccFvGnY0iRJ0+QngSWpUQaAJDXKAJCkRhkAktSo1Ard/SLJIvDl03z6WuCJActZbRy/43f87XppVV00xAtNNAtoGqpq9nSfm+RgVc0NWc9q4vgdv+Nve/xDvZaXgCSpUQaAJDVqtQbAnpUuYIU5/rY5/rYNNv4VexNYkrSyVusZgCTpGTIAJKlRqy4AlrtB/WqVZG+SY0keHGt7fpJPJPli9/15Y/ve2h2Dw0muHmt/eZLPdfvek2Spm/WcVZJsSPLJJA8lOZTkzV17K+P/viSfSXJ/N/4/6NqbGD+M7j2e5LNJPtZtNzN2gCSPdrXfd2Ka5xk5BlW1ar4YLUf9JeDFwPnA/cDWla5roLH9FHA58OBY2x8Cu7rHu4B3do+3dmO/ANjcHZOZbt9ngJ9gdJe2jwPbV3psE4z9EuDy7vFFwMPdGFsZf4ALu8fnAf8MXNnK+Lu6fxv4S+Bj3XYzY+9qfxRY22ub+jFYbWcA37lBfVU9CZy4Qf2qV1WfBr7aa94BfLB7/EHgl8ba91XV/1TVI4zuw3BFkkuA51TVP9Xof8PtY885a1XV41X1L93jrwMPMbqndCvjr6o6cSPi87qvopHxJ1kPXAt8YKy5ibEvY+rHYLUFwMluPn+uelF1d1brvr+waz/ZcVjXPe63rxpJNgE/zuiv4GbG310CuQ84Bnyiqloa/7uB3wWeGmtrZewnFPB3Se5NsrNrm/oxWLGlIE7TRDefb8DJjsOqPj5JLgQ+DPxWVf33KS5fnnPjr6pvAy9LcjHwkSQ/doru58z4k/wCcKyq7k1y1SRPWaJtVY6951VVdTTJC4FPJPnCKfoOdgxW2xlAazef//futI7u+7Gu/WTHYaF73G8/6yU5j9Ev/7+oqju65mbGf0JV/RfwKWAbbYz/VcAvJnmU0SXdn0ny57Qx9u+oqqPd92PARxhd7p76MVhtATDJDerPJfuBN3SP3wB8dKz9uiQXJNkMbAE+050mfj3Jld27/zeMPees1dX6Z8BDVfUnY7taGf9s95c/SZ4N/BzwBRoYf1W9tarWV9UmRj/P/1BVr6eBsZ+Q5AeSXHTiMfBa4EHOxDFY6Xe/T+Pd8msYzRL5EvC2la5nwHF9CHgc+F9GSf5G4AXA3wNf7L4/f6z/27pjcJixd/qBue4/z5eA99J92vts/gJ+ktGp6gPAfd3XNQ2N/1Lgs934HwTe3rU3Mf6x2q/i/2cBNTN2RrMa7+++Dp34vXYmjoFLQUhSo1bbJSBJ0kAMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSo/wOioGDZSic+nwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main part of code, Building architecture and training for the Pain labels\n",
    "\n",
    "# Device configuration for CPU or GPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Hyper-parameters \n",
    "# input_size = 18 AU (Both presence(1) and intensities(17) )\n",
    "num_classes = 2 ## (Binary classification as pain(0) or no pain(1) )\n",
    "num_epochs = 1\n",
    "batch_size = 1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "input_size = 18\n",
    "sequence_length = 30\n",
    "hidden_size = 50\n",
    "num_layers = 5\n",
    "\n",
    "\n",
    "## PAIN DATASET\n",
    "\n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "        \n",
    "        # or:\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # Can add sigmoid here itself ################################################## \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.ones(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.ones(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        # Check list sizes here to match required lengths\n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # out: (n, 28, 128)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]\n",
    "        # out: (n, 128)\n",
    "#         F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "        out = self.fc(out)\n",
    "        out= F.log_softmax((out),dim=1)\n",
    "        # out: (n, 2)\n",
    "        return out\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer setting\n",
    "# criterion = nn.CrossEntropyLoss() ## Useful for later stage where we might have to use pain levels\n",
    "criterion = nn.NLLLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "m = nn.Sigmoid()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "## Hinge loss try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─LSTM: 1-1                              95,600\n",
      "├─Linear: 1-2                            102\n",
      "=================================================================\n",
      "Total params: 95,702\n",
      "Trainable params: 95,702\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "RNN(\n",
      "  (lstm): LSTM(18, 50, num_layers=5, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(1,5,18))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1000/11172], Loss: 0.001160\n",
      "Epoch [1/1], Step [2000/11172], Loss: 0.000426\n",
      "Epoch [1/1], Step [3000/11172], Loss: 0.000204\n",
      "Epoch [1/1], Step [4000/11172], Loss: 0.000109\n",
      "Epoch [1/1], Step [5000/11172], Loss: 0.000062\n",
      "Epoch [1/1], Step [6000/11172], Loss: 0.019085\n",
      "Epoch [1/1], Step [7000/11172], Loss: 0.002093\n",
      "Epoch [1/1], Step [8000/11172], Loss: 0.000873\n",
      "Epoch [1/1], Step [9000/11172], Loss: 0.000473\n",
      "Epoch [1/1], Step [10000/11172], Loss: 0.000284\n",
      "Epoch [1/1], Step [11000/11172], Loss: 0.000180\n"
     ]
    }
   ],
   "source": [
    "## Pain label training for the LSTM model\n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_x)\n",
    "i=0\n",
    "\n",
    "loss_count=[]\n",
    "for epoch in range(num_epochs):\n",
    "    loss_value=0.0\n",
    "    for features, labels in zip(train_x,train_y): \n",
    "        \n",
    "        features = features.reshape(-1, sequence_length, input_size).to(device)\n",
    "#         print(features.shape)\n",
    "        labels = labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "#         print(len(labels),len(m(outputs)[0]))\n",
    "#         print(\"sh\",features.shape)\n",
    "#         print('out',outputs.shape)\n",
    "#         print('lab',labels.shape)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i+=1\n",
    "        loss_value+=loss.item()\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.6f}')\n",
    "    loss_count.append(loss_value/len(train_x))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03144125911435141]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1492e3c56d8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE MODEL\n",
    "\n",
    "# PATH =r'C:\\Users\\Nischal\\Desktop\\LSTM model\\saved_model\\pain_model.pth'\n",
    "# torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(PATH, map_location=torch.device('cuda')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test data: 50.314465408805034 %\n"
     ]
    }
   ],
   "source": [
    "## Testing the model for both labels\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for features, labels in zip(test_x,test_y):\n",
    "        features = features.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels=labels.to(device)\n",
    "        \n",
    "        outputs = model(features)\n",
    "#         print(outputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on test data: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model for pain labels\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# # Test the model\n",
    "# # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "# with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0\n",
    "#     for features, labels in zip(OP_test_x,OP_test_y):\n",
    "        \n",
    "#         features = features.reshape(-1, sequence_length, input_size).to(device)\n",
    "        \n",
    "#         outputs = model(features)\n",
    "# #         print(outputs)\n",
    "#         labels=labels.to(device)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "# #         print(predicted)\n",
    "#         n_samples += labels.size(0)\n",
    "#         n_correct += (predicted == labels.long()).sum().item()\n",
    "\n",
    "#     acc = 100.0 * n_correct / n_samples\n",
    "#     print(f'Accuracy of the network on test data: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-260f541401b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'output_list' is not defined"
     ]
    }
   ],
   "source": [
    "len(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
